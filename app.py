import os
import json
import gdown
import onnxruntime as ort
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from PIL import Image
import numpy as np
from io import BytesIO

app = FastAPI()

# ğŸ”— ÄÆ°á»ng dáº«n model (Google Drive - Link táº£i trá»±c tiáº¿p)
MODEL_URL = "https://drive.google.com/uc?id=1W-WM4IaS_XXLzI6wgbiruzyuzoFkniSv"
MODEL_PATH = "./image_caption_model.onnx"
VOCAB_PATH = "./tokenizer/vocab.json"

# ğŸ“¥ HÃ m táº£i mÃ´ hÃ¬nh tá»« Google Drive náº¿u chÆ°a cÃ³
def download_model():
    if not os.path.exists(MODEL_PATH):
        print("ğŸ“¥ Downloading model from Google Drive...")
        gdown.download(MODEL_URL, MODEL_PATH, quiet=False)
        print("âœ… Model downloaded successfully!")

download_model()

# ğŸ›  Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a mÃ´ hÃ¬nh
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh táº¡i: {MODEL_PATH}")

# ğŸ” Kiá»ƒm tra file tá»« Ä‘iá»ƒn náº¿u cÃ³
if not os.path.exists(VOCAB_PATH):
    print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y tá»« Ä‘iá»ƒn táº¡i {VOCAB_PATH}. API cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng khÃ´ng chÃ­nh xÃ¡c.")
    vocab = {}
else:
    with open(VOCAB_PATH, "r", encoding="utf-8") as f:
        try:
            vocab = json.load(f)
            print(f"âœ… Táº£i tá»« vá»±ng thÃ nh cÃ´ng, tá»•ng sá»‘ tá»«: {len(vocab)}")
        except json.JSONDecodeError:
            raise ValueError(f"âŒ Lá»—i khi Ä‘á»c file tá»« Ä‘iá»ƒn: {VOCAB_PATH}")

# ğŸ—‚ Äáº£m báº£o vocab Ä‘Ãºng Ä‘á»‹nh dáº¡ng {int: str}
try:
    id_to_word = {int(k): v for k, v in vocab.items()} if vocab else {}
except ValueError:
    raise ValueError("âŒ Lá»—i khi chuyá»ƒn Ä‘á»•i vocab, cÃ³ thá»ƒ cÃ³ key khÃ´ng pháº£i sá»‘ nguyÃªn.")

# ğŸš€ Load mÃ´ hÃ¬nh ONNX
try:
    ort_session = ort.InferenceSession(MODEL_PATH)
    print("âœ… MÃ´ hÃ¬nh ONNX Ä‘Ã£ load thÃ nh cÃ´ng!")
except Exception as e:
    raise RuntimeError(f"âŒ Lá»—i khi load mÃ´ hÃ¬nh ONNX: {str(e)}")

# ğŸ›  Kiá»ƒm tra input/output cá»§a mÃ´ hÃ¬nh ONNX
print("ğŸ“Š TÃªn Ä‘áº§u vÃ o cá»§a mÃ´ hÃ¬nh:", [inp.name for inp in ort_session.get_inputs()])
print("ğŸ“Š TÃªn Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh:", [out.name for out in ort_session.get_outputs()])

# ğŸ“œ HÃ m giáº£i mÃ£ token thÃ nh caption
def decode_tokens(token_ids):
    if not isinstance(token_ids, list):
        token_ids = [token_ids]

    words = [id_to_word.get(token_id, "[UNK]") for token_id in token_ids]
    words = [word for word in words if word not in ["[PAD]", "[START]", "[END]", "[UNK]"]]
    caption = " ".join(words).capitalize() + "."
    return caption

# ğŸ“· HÃ m tiá»n xá»­ lÃ½ áº£nh
def preprocess_image(image: Image.Image):
    image = image.resize((224, 224))
    image_array = np.array(image).astype(np.float32) / 255.0
    image_array = np.transpose(image_array, (2, 0, 1))
    return np.expand_dims(image_array, axis=0)

# ğŸ“ API kiá»ƒm tra káº¿t ná»‘i
@app.get("/")
def read_root():
    return {"message": "âœ… API cháº¡y thÃ nh cÃ´ng trÃªn Render!"}

# ğŸ”¥ API dá»± Ä‘oÃ¡n caption tá»« áº£nh
@app.post("/predict/")
async def predict(image: UploadFile = File(...)):
    try:
        contents = await image.read()
        img = Image.open(BytesIO(contents)).convert("RGB")
        print("ğŸ“¸ áº¢nh nháº­n Ä‘Æ°á»£c!")

        processed_image = preprocess_image(img)
        print("âœ… áº¢nh Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½:", processed_image.shape)

        dummy_caption = np.random.randint(0, len(id_to_word), (1, 10)).astype(np.int64)
        dummy_attention_mask = np.ones_like(dummy_caption).astype(np.int64)

        print("ğŸ“œ Dummy caption:", dummy_caption)
        print("ğŸ“œ Attention mask:", dummy_attention_mask)

        # Kiá»ƒm tra tÃªn Ä‘áº§u vÃ o mÃ´ hÃ¬nh ONNX
        model_inputs = ort_session.get_inputs()
        input_names = [inp.name for inp in model_inputs]
        print("ğŸ“Š TÃªn Ä‘áº§u vÃ o mÃ´ hÃ¬nh:", input_names)

        # Táº¡o inputs Ä‘Ãºng theo tÃªn
        inputs = {
            input_names[0]: processed_image,
            input_names[1]: dummy_caption,
            input_names[2]: dummy_attention_mask
        }
        print("ğŸ“¤ Gá»­i dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh:", {k: v.shape for k, v in inputs.items()})

        outputs = ort_session.run(None, inputs)
        print("ğŸ“¥ Nháº­n output tá»« mÃ´ hÃ¬nh:", [o.shape for o in outputs])

        # Kiá»ƒm tra output cÃ³ Ä‘Ãºng format khÃ´ng
        if len(outputs) == 0:
            raise ValueError("âŒ MÃ´ hÃ¬nh khÃ´ng tráº£ vá» output nÃ o!")

        token_ids = np.argmax(outputs[0], axis=-1)[0]
        print("ğŸ“ Token IDs:", token_ids)

        caption = decode_tokens(token_ids)
        print("ğŸ—£ Caption:", caption)

        return JSONResponse(content={"caption": caption})
    except Exception as e:
        print("âŒ Lá»—i:", str(e))
        return JSONResponse(status_code=500, content={"error": str(e)})

# ğŸŒ Cháº¡y á»©ng dá»¥ng
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
