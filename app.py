import os
import json
import torch
import requests
import numpy as np
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from PIL import Image
from io import BytesIO
from model import ImageCaptionModel  # Import model tá»« model.py
from transformers import AutoTokenizer  # Import tokenizer

app = FastAPI()

# ğŸ“¥ Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n
MODEL_PATH = "./swinv2_transformerdecoder.pth"
TOKENIZER_PATH = "./tokenizer"
HUGGINGFACE_MODEL_URL = "https://huggingface.co/NguyenKhiem/SwinV2Transformer/resolve/main/swinv2_transformerdecoder.pth"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ“¥ Táº£i mÃ´ hÃ¬nh tá»« Hugging Face náº¿u chÆ°a cÃ³
if not os.path.exists(MODEL_PATH):
    print("ğŸ”„ Äang táº£i mÃ´ hÃ¬nh tá»« Hugging Face...")
    response = requests.get(HUGGINGFACE_MODEL_URL)
    if response.status_code == 200:
        with open(MODEL_PATH, "wb") as f:
            f.write(response.content)
        print("âœ… Táº£i mÃ´ hÃ¬nh thÃ nh cÃ´ng!")
    else:
        raise FileNotFoundError(f"âŒ KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh, mÃ£ lá»—i: {response.status_code}")

# Khá»Ÿi táº¡o model
model = ImageCaptionModel()  
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))  # Load trá»ng sá»‘
model.to(DEVICE)
model.eval()  # Chuyá»ƒn sang cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡

# ğŸ“œ Táº£i tokenizer
if not os.path.exists(TOKENIZER_PATH):
    raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y tokenizer táº¡i: {TOKENIZER_PATH}")

tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)  # Load tokenizer

# ğŸ“œ HÃ m giáº£i mÃ£ token thÃ nh caption
def decode_tokens(token_ids):
    words = tokenizer.decode(token_ids, skip_special_tokens=True)  # DÃ¹ng tokenizer Ä‘á»ƒ giáº£i mÃ£
    return words.capitalize() + "."

# ğŸ“· Tiá»n xá»­ lÃ½ áº£nh
def preprocess_image(image: Image.Image):
    image = image.resize((224, 224))
    image_array = np.array(image).astype(np.float32) / 255.0
    image_array = np.transpose(image_array, (2, 0, 1))
    image_tensor = torch.tensor(image_array, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    return image_tensor

# ğŸ“ API kiá»ƒm tra káº¿t ná»‘i
@app.get("/")
def read_root():
    return {"message": "âœ… API Ä‘ang cháº¡y thÃ nh cÃ´ng trÃªn Render!"}

# ğŸ”¥ API dá»± Ä‘oÃ¡n caption tá»« áº£nh
@app.post("/predict/")
async def predict(image: UploadFile = File(...)):
    try:
        contents = await image.read()
        img = Image.open(BytesIO(contents)).convert("RGB")

        # Tiá»n xá»­ lÃ½ áº£nh
        image_tensor = preprocess_image(img)

        # Táº¡o Ä‘áº§u vÃ o ban Ä‘áº§u cho Transformer Decoder (thÆ°á»ng lÃ  token <START>)
        start_token = torch.tensor([tokenizer.bos_token_id], dtype=torch.long).unsqueeze(0).to(DEVICE)

        # Cháº¡y mÃ´ hÃ¬nh Ä‘á»ƒ táº¡o caption
        with torch.no_grad():
            generated_tokens = model(image_tensor, start_token)

        # Láº¥y token cÃ³ xÃ¡c suáº¥t cao nháº¥t
        token_ids = torch.argmax(generated_tokens, dim=-1).cpu().numpy()[0]

        # Giáº£i mÃ£ token thÃ nh caption
        caption = decode_tokens(token_ids)

        return JSONResponse(content={"caption": caption})
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})
